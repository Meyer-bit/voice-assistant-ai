{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ve3sMC5RRxFJ"
      },
      "outputs": [],
      "source": [
        "language = 'pt'\n",
        "\n",
        "from IPython.display import Audio, display, Javascript\n",
        "from google.colab import output\n",
        "from base64 import b64decode\n",
        "\n",
        "# ===============================\n",
        "# GRAVA√á√ÉO DE √ÅUDIO (JS)\n",
        "# ===============================\n",
        "RECORD = \"\"\"\n",
        "const sleep  = time => new Promise(resolve => setTimeout(resolve, time))\n",
        "const b2text = blob => new Promise(resolve => {\n",
        "  const reader = new FileReader()\n",
        "  reader.onloadend = e => resolve(e.srcElement.result)\n",
        "  reader.readAsDataURL(blob)\n",
        "})\n",
        "var record = time => new Promise(async resolve => {\n",
        "  stream = await navigator.mediaDevices.getUserMedia({ audio: true })\n",
        "  recorder = new MediaRecorder(stream)\n",
        "  chunks = []\n",
        "  recorder.ondataavailable = e => chunks.push(e.data)\n",
        "  recorder.start()\n",
        "  await sleep(time)\n",
        "  recorder.onstop = async ()=>{\n",
        "    blob = new Blob(chunks)\n",
        "    text = await b2text(blob)\n",
        "    resolve(text)\n",
        "  }\n",
        "  recorder.stop()\n",
        "})\n",
        "\"\"\"\n",
        "\n",
        "def record(sec=5):\n",
        "  display(Javascript(RECORD))\n",
        "  js_result = output.eval_js('record(%s)' % (sec * 1000))\n",
        "  audio = b64decode(js_result.split(',')[1])\n",
        "\n",
        "  arquivo_voz = 'request_audio.wav'\n",
        "  with open(arquivo_voz, 'wb') as abrir:\n",
        "    abrir.write(audio)\n",
        "\n",
        "  return f'/content/{arquivo_voz}'\n",
        "\n",
        "\n",
        "# ===============================\n",
        "# OUVINDO O USU√ÅRIO\n",
        "# ===============================\n",
        "print('üé§ Ouvindo...\\n')\n",
        "record_file = record()\n",
        "display(Audio(record_file, autoplay=False))\n",
        "\n",
        "\n",
        "# ===============================\n",
        "# WHISPER - TRANSCRI√á√ÉO\n",
        "# ===============================\n",
        "!pip install git+https://github.com/openai/whisper.git -q\n",
        "import whisper\n",
        "\n",
        "model = whisper.load_model(\"small\")\n",
        "result = model.transcribe(record_file, fp16=False, language=language)\n",
        "transcription = result[\"text\"]\n",
        "\n",
        "print(\"üìù Transcri√ß√£o:\", transcription)\n",
        "\n",
        "\n",
        "# ===============================\n",
        "# OPENAI CONFIG\n",
        "# ===============================\n",
        "!pip install openai\n",
        "import os\n",
        "import openai\n",
        "from getpass import getpass\n",
        "\n",
        "# Solicita a API Key sem expor no c√≥digo\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass(\"Digite sua OpenAI API Key: \")\n",
        "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
        "\n",
        "\n",
        "# =====================================================\n",
        "#  PROMPT DE SISTEMA + MEM√ìRIA DE CONVERSA\n",
        "# =====================================================\n",
        "conversation_history = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": (\n",
        "            \"Voc√™ √© uma assistente de voz educada, clara e objetiva. \"\n",
        "            \"Explique conceitos de forma simples e direta, como para iniciantes.\"\n",
        "        )\n",
        "    }\n",
        "]\n",
        "\n",
        "\n",
        "# =====================================================\n",
        "# COMANDOS DE VOZ\n",
        "# =====================================================\n",
        "transcription_lower = transcription.lower()\n",
        "\n",
        "if \"limpar conversa\" in transcription_lower:\n",
        "    conversation_history.clear()\n",
        "    conversation_history.append({\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"Voc√™ √© uma assistente de voz educada e objetiva.\"\n",
        "    })\n",
        "    chatgpt_response = \"Conversa limpa com sucesso. Podemos come√ßar de novo.\"\n",
        "\n",
        "elif \"encerrar assistente\" in transcription_lower:\n",
        "    chatgpt_response = \"Assistente encerrado. At√© mais!\"\n",
        "\n",
        "else:\n",
        "    # Adiciona a fala do usu√°rio ao hist√≥rico\n",
        "    conversation_history.append({\n",
        "        \"role\": \"user\",\n",
        "        \"content\": transcription\n",
        "    })\n",
        "\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=conversation_history\n",
        "    )\n",
        "\n",
        "    chatgpt_response = response.choices[0].message.content\n",
        "\n",
        "    # Adiciona resposta ao hist√≥rico\n",
        "    conversation_history.append({\n",
        "        \"role\": \"assistant\",\n",
        "        \"content\": chatgpt_response\n",
        "    })\n",
        "\n",
        "print(\"ü§ñ Assistente:\", chatgpt_response)\n",
        "\n",
        "\n",
        "# ===============================\n",
        "# TEXTO ‚Üí VOZ (gTTS)\n",
        "# ===============================\n",
        "!pip install gTTS\n",
        "from gtts import gTTS\n",
        "\n",
        "gtts_object = gTTS(\n",
        "    text=chatgpt_response,\n",
        "    lang=language,\n",
        "    slow=False\n",
        ")\n",
        "\n",
        "response_audio = \"/content/response_audio.wav\"\n",
        "gtts_object.save(response_audio)\n",
        "\n",
        "display(Audio(response_audio, autoplay=True))\n"
      ]
    }
  ]
}